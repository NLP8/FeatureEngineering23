{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saaO06RMwzGH"
      },
      "source": [
        "# Hoja de Trabajo \\# 5\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "por Josué Obregón <br>\n",
        "DS6011 - Feature Engineering <br>\n",
        "UVG Masters - Escuela de Negocios<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0-nImUHNxOv"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "El objetivo de esta hoja de trabajo  es presentar al estudiante diferentes técnicas de extracción y generación de atributos.\n",
        "\n",
        "También se busca que el estudiante practique la utilización de éstas técnicas con las librerías disponibles en el lenguaje Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYjZ_KEuTCTe"
      },
      "source": [
        "## Importación de librerías y carga de los datos\n",
        "\n",
        "Las librerías que importaremos para empezar son pandas y numpy para el manejo de los datos, y matplotlib, seaborn y plotly para la generación de visualizaciones. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoXELFC48mlh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndtakjmx8rQs"
      },
      "source": [
        "# Dimensionality reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-0etrH4ChqZ"
      },
      "source": [
        "## Ejemplo con datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aI1NNgR8tAJ"
      },
      "source": [
        "df_test = pd.DataFrame({\n",
        "... 'Gene1': [10,11,8,3,2,1],\n",
        "... 'Gene2': [6,4,5,3,2.8,1],\n",
        "... 'Gene3': [12,9,10,2.5,1.3,2],\n",
        "... 'Gene4': [5,7,6,2,4,7]\n",
        "... }, index=['Mouse1','Mouse2','Mouse3','Mouse4','Mouse5','Mouse6'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cje97qC09st8"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJF7F6F_9tV-"
      },
      "source": [
        "sns.scatterplot(data=df_test,  x='Gene1',y='Gene2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZWP21J0-e8r"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na78HArY-7rL"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_EejDf3-9my"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqyroGKU--m9"
      },
      "source": [
        "pca = PCA()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIWjB07n--q-"
      },
      "source": [
        "pca.fit(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtn9eKqQ_XyQ"
      },
      "source": [
        "pca_proj = pd.DataFrame(pca.transform(df_test), columns=['Component1','Component2','Component3','Component4'], index = df_test.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yELTJrHn_X5N"
      },
      "source": [
        "pca_proj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuGE07c__7Pl"
      },
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxQbq1_aN-2F"
      },
      "source": [
        "pca.explained_variance_ratio_.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z760hHKn_X8R"
      },
      "source": [
        "sns.scatterplot(data=pca_proj,  x='Component1',y='Component2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YcYg7H2OPhu"
      },
      "source": [
        "sns.scatterplot(data=pca_proj,  x='Component2',y='Component3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0tWwtcW--7p"
      },
      "source": [
        "### NMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk8PHMDk_DL2"
      },
      "source": [
        "from sklearn.decomposition import NMF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et3nI2To_HFG"
      },
      "source": [
        "nmf = NMF(n_components=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjLe2uIw_Thb"
      },
      "source": [
        "nmf.fit(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZH-aqN-ASMG"
      },
      "source": [
        "nmf_proj = pd.DataFrame(nmf.transform(df_test), columns=['Component1','Component2'], index = df_test.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPwQRmiNASMG"
      },
      "source": [
        "nmf_proj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRvp0AWFAWFG"
      },
      "source": [
        "sns.scatterplot(data=nmf_proj,  x='Component1',y='Component2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mj7BFV_AZLN"
      },
      "source": [
        "print('Dimensiones de los datos proyectados: ',nmf_proj.shape)\n",
        "print('Dimensiones de la matriz H: ', nmf.components_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9dbpQJbBDkR"
      },
      "source": [
        "  # X ≈ W x H\n",
        "np.matmul(nmf_proj.to_numpy(),nmf.components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru69wQimCBuL"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPgZ8CNCCXve"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjnpR9a-njQB"
      },
      "source": [
        "# Ejemplo con los datos de pasajeros en Chicago"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBRl7VGfALex"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR1uTokC8Wzi"
      },
      "source": [
        "import gdown\n",
        "\n",
        "urls = ['https://drive.google.com/uc?export=download&id=1QvHTL7yok7oHX0TmuSm8OMpvxnItjT_s', # training  https://drive.google.com/file/d/1QvHTL7yok7oHX0TmuSm8OMpvxnItjT_s/view?usp=sharing  \n",
        "        'https://drive.google.com/uc?export=download&id=1nWcvoCkgUeCr-AT45JSsqKcSBUr1YbpU', # testing https://drive.google.com/file/d/1nWcvoCkgUeCr-AT45JSsqKcSBUr1YbpU/view?usp=sharing\n",
        "        'https://drive.google.com/uc?export=download&id=1LIK0YFER5ve9Wn7Uap4Zb6f5pXcAExZ-', # train_days   https://drive.google.com/file/d/1LIK0YFER5ve9Wn7Uap4Zb6f5pXcAExZ-/view?usp=sharing \n",
        "        'https://drive.google.com/uc?export=download&id=16AGQw1nM9NYILv2aSZaSNSn9jBPByWPq', # okc_train  https://drive.google.com/file/d/16AGQw1nM9NYILv2aSZaSNSn9jBPByWPq/view?usp=sharing\n",
        "        ]\n",
        "outputs = ['training_proj.csv','testing_proj.csv', 'train_days.csv','okc_train.csv']\n",
        "\n",
        "for url,output in zip(urls,outputs):\n",
        "  gdown.download(url, f'data/{output}', quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0mp-gb-npxS"
      },
      "source": [
        "training = pd.read_csv('data/training_proj.csv', parse_dates=True, index_col=0)\n",
        "testing = pd.read_csv('data/testing_proj.csv', parse_dates=True, index_col=1)\n",
        "train_days = pd.read_csv('data/train_days.csv',index_col=1, parse_dates=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqxiddoXoM29"
      },
      "source": [
        "training.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCX6-Rm6sUon"
      },
      "source": [
        "testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4bz6mgmtH5E"
      },
      "source": [
        "weekends = training[training['dow'].isin(['Sat','Sun'])].filter(regex=(\"(l14_[0-9]|s_40380)\"), axis=1).copy()\n",
        "print(weekends.to_numpy().shape)\n",
        "weekends.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyeUt84qtJ2k"
      },
      "source": [
        "weekend_days = train_days[train_days.index.dayofweek>4].copy()\n",
        "print(weekend_days.index[0])\n",
        "print(weekend_days.index[-1])\n",
        "print(len(weekend_days))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ox0ZTg_8dSM"
      },
      "source": [
        "Utilizaremos a manera de ejemplo una librería para validación de series de tiempo [tscv](https://github.com/WenjieZ/TSCV) [Artículo informativo](https://www.zhengwenjie.net/tscv/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFnZY2zk0cYs"
      },
      "source": [
        "!pip install tscv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_AknX42tJ5M"
      },
      "source": [
        "from tscv import GapRollForward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgnP9tvstJ8Y"
      },
      "source": [
        "ts_cv= GapRollForward(min_train_size=1600,min_test_size=4,max_test_size= 4,roll_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h6pFzJ4xpKO"
      },
      "source": [
        "i=1\n",
        "for train_index, test_index in ts_cv.split( weekend_days):\n",
        "  print(f'Training Split {i}: {train_index.shape} -- Testing Split {i}: {test_index.shape}')\n",
        "  i=i+1\n",
        "  # print(train_index[0])\n",
        "  # print(train_index[-1])\n",
        "  # print(test_index[0])\n",
        "  # print(test_index[-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-viIdkCY2tr4"
      },
      "source": [
        "# Taken from https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py \n",
        "from matplotlib.patches import Patch\n",
        "cmap_data = plt.cm.Paired\n",
        "cmap_cv = plt.cm.coolwarm\n",
        "n_splits = 25\n",
        "def plot_cv_indices(cv, X, y,  ax, n_splits, lw=10):\n",
        "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
        "\n",
        "    # Generate the training/testing visualizations for each CV split\n",
        "    for ii, (tr, tt) in enumerate(cv.split(X=X)):\n",
        "        # Fill in indices with the training/test groups\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[tt] = 1\n",
        "        indices[tr] = 0\n",
        "\n",
        "        # Visualize the results\n",
        "        x_labels = [weekend_days.index[idx].strftime('%Y-%m-%d') for idx in range(len(indices))]        \n",
        "       #print(len(x_labels))\n",
        "       # print(len([ii + .5] * len(indices)))\n",
        "        ax.scatter(x_labels, [ii + .5] * len(indices),\n",
        "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
        "                   vmin=-.2, vmax=1.2)\n",
        "\n",
        "\n",
        "    # Formatting\n",
        "    yticklabels = list(range(n_splits)) \n",
        "    ax.set(yticks=np.arange(n_splits) + .5, yticklabels=yticklabels,\n",
        "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
        "             xlim=[1585, 1630])\n",
        "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
        "    plt.xticks(rotation='vertical')\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC-wD8NGxpNY"
      },
      "source": [
        "groups = np.hstack([[ii] * 25 for ii in range(25)])\n",
        "fig, ax = plt.subplots(figsize=(16, 6))\n",
        "plot_cv_indices(ts_cv, weekends, None,  ax, n_splits)\n",
        "\n",
        "ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
        "          ['Testing set', 'Training set'], loc=(1.02, .8))\n",
        "# Make the legend fit\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_qsXtN7xpQT"
      },
      "source": [
        "X_train = weekends.drop(['s_40380'],axis=1) # Variables predictoras X\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePSWOZhB-vVv"
      },
      "source": [
        "y_train = weekends['s_40380'] # Variable respuesta Y\n",
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn5E2PmsIgxF"
      },
      "source": [
        "### Baseline con regresión lineal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H74AGyrp-xR1"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ZGtnorAcP1"
      },
      "source": [
        "lr = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSGe5yuGAp57"
      },
      "source": [
        "cross_val  = cross_val_score( lr, X_train, y_train, cv=ts_cv, scoring='neg_root_mean_squared_error')\n",
        "print(cross_val*-1)\n",
        "print(f'Mean: {cross_val.mean()*-1}, Std: {cross_val.std()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH_9wVQKA6wP"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD15WCT5BvM3"
      },
      "source": [
        "pca_stations = PCA(n_components=20,random_state=6011)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69SGJtu2B1ar"
      },
      "source": [
        "pca_stations.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56qoWt7SDjua"
      },
      "source": [
        "print(pca_stations.n_components_)\n",
        "print(pca_stations.components_.shape) #eigenvectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDO-qtpMSM49"
      },
      "source": [
        "variance_ration_cumsum = np.cumsum(np.pad(pca_stations.explained_variance_ratio_, (1, 0), \"constant\"))\n",
        "variance_ration_cumsum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4WMqOqOQiK5"
      },
      "source": [
        "fig =px.line(x=range(21), y=variance_ration_cumsum, width=500, height=500)\n",
        "fig.update_yaxes(range=[-0.02, 1.02])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvCaZn2PGf6n"
      },
      "source": [
        "projected_pca_stations = pca_stations.transform(X_train)\n",
        "projected_pca_stations = pd.DataFrame(projected_pca_stations, columns=[f'Component{i+1}' for i in range(20)])\n",
        "projected_pca_stations.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COuY-gC2QnOb"
      },
      "source": [
        "from plotly.subplots import make_subplots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo8IMJH9GN2z"
      },
      "source": [
        "#fig, axes = plt.subplots( nrows=5,n_cols=1)\n",
        "fig = make_subplots( rows=1, cols=5, subplot_titles=[f'Component{i+1}' for i in range(5)],\n",
        "                    column_widths=[50 for i in range(5)], row_heights=[50 ])\n",
        "for i in range(1,6):\n",
        "  scat = px.scatter( data_frame=projected_pca_stations, x=f'Component{i}', \n",
        "  y=y_train, color_discrete_sequence=['black'], opacity=0.3,\n",
        "   trendline='ols' )\n",
        "  fig.add_trace(scat.data[0], col=i, row=1)\n",
        "  fig.add_trace(scat.data[1], col=i, row=1)\n",
        "fig.update_layout(\n",
        "    height=300, width=1500,\n",
        "    margin=dict(l=5, r=5, t=30, b=5),\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us7UeOKOGBEY"
      },
      "source": [
        "## NMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n29Q_51RGFUD"
      },
      "source": [
        "nfm_stations = NMF(n_components=20, random_state=6011)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzgLXUmGFUD"
      },
      "source": [
        "nfm_stations.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZf9zvnNGDjE"
      },
      "source": [
        "nfm_stations.reconstruction_err_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuRWIRMPGDlp"
      },
      "source": [
        "projected_nfm_stations = nfm_stations.transform(X_train)\n",
        "projected_nfm_stations = pd.DataFrame(projected_nfm_stations, columns=[f'Component{i+1}' for i in range(20)])\n",
        "projected_nfm_stations.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHBj952GDos"
      },
      "source": [
        "#fig, axes = plt.subplots( nrows=5,n_cols=1)\n",
        "fig = make_subplots( rows=1, cols=15, subplot_titles=[f'Component{i+1}' for i in range(15)],\n",
        "                    column_widths=[50 for i in range(15)], row_heights=[50 ])\n",
        "for i in range(1,15):\n",
        "  scat = px.scatter( data_frame=projected_nfm_stations, x=f'Component{i}', \n",
        "  y=y_train, color_discrete_sequence=['black'], opacity=0.3,\n",
        "   trendline='ols' )\n",
        "  fig.add_trace(scat.data[0], col=i, row=1)\n",
        "  fig.add_trace(scat.data[1], col=i, row=1)\n",
        "fig.update_layout(\n",
        "    height=300, width=2500,\n",
        "    margin=dict(l=5, r=5, t=30, b=5),\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICkVKfzTWKa8"
      },
      "source": [
        "## PLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrAHRaaCWM3E"
      },
      "source": [
        "from sklearn.cross_decomposition import PLSCanonical,PLSRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxfb3ew1WKa8"
      },
      "source": [
        "pls_stations = PLSRegression(n_components=20 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwHV4kzQWKa9"
      },
      "source": [
        "pls_stations.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_33A80nddLTQ"
      },
      "source": [
        "pls_stations.x_scores_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSEoHh6AWKa9"
      },
      "source": [
        "projected_pls_stations = pls_stations.transform(X_train)\n",
        "projected_pls_stations = pd.DataFrame(projected_pls_stations, columns=[f'Component{i+1}' for i in range(20)])\n",
        "projected_pls_stations.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEdenYhAWKa9"
      },
      "source": [
        "#fig, axes = plt.subplots( nrows=5,n_cols=1)\n",
        "fig = make_subplots( rows=1, cols=5, subplot_titles=[f'Component{i+1}' for i in range(5)],\n",
        "                    column_widths=[50 for i in range(5)], row_heights=[50 ])\n",
        "for i in range(1,6):\n",
        "\n",
        "  #PLS\n",
        "  scat3 = px.scatter( data_frame=projected_pls_stations, x=f'Component{i}', \n",
        "  y=y_train, color_discrete_sequence=['black'], opacity=0.3,\n",
        "   trendline='ols' )\n",
        "  fig.add_trace(scat3.data[0], col=i, row=1)\n",
        "  fig.add_trace(scat3.data[1], col=i, row=1)\n",
        "fig.update_layout(\n",
        "    height=300, width=1200,\n",
        "    margin=dict(l=5, r=5, t=30, b=5),\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeLQWr5DoEJj"
      },
      "source": [
        "### Gráfica de resumen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6or2EYUoEn8"
      },
      "source": [
        "#fig, axes = plt.subplots( nrows=5,n_cols=1)\n",
        "fig = make_subplots( rows=5, cols=3, row_titles=[f'Component{i+1}' for i in range(5)],\n",
        "                     horizontal_spacing=0.01, vertical_spacing=0.01,  shared_xaxes=True,\n",
        "                     column_titles=['PCA', 'NFM', 'PLS'])\n",
        "for i in range(1,6):\n",
        "  #PCA\n",
        "  scat = px.scatter( data_frame=projected_pca_stations, x=f'Component{i}', \n",
        "  y=y_train, color_discrete_sequence=['black'], opacity=0.3,\n",
        "   trendline='ols' )\n",
        "  fig.add_trace(scat.data[0], col=1, row=i)\n",
        "  fig.add_trace(scat.data[1], col=1, row=i)\n",
        "\n",
        "  #NMF\n",
        "  scat2 = px.scatter( data_frame=projected_nfm_stations, x=f'Component{i}', \n",
        "  y=y_train, color_discrete_sequence=['black'], opacity=0.3,\n",
        "   trendline='ols' )\n",
        "  fig.add_trace(scat2.data[0], col=2, row=i)\n",
        "  fig.add_trace(scat2.data[1], col=2, row=i)\n",
        "\n",
        "  #PLS\n",
        "  scat = px.scatter( data_frame=projected_pls_stations, x=f'Component{i}', \n",
        "  y=y_train, color_discrete_sequence=['black'], opacity=0.3,\n",
        "   trendline='ols' )\n",
        "  fig.add_trace(scat.data[0], col=3, row=i)\n",
        "  fig.add_trace(scat.data[1], col=3, row=i)\n",
        "fig.update_layout(\n",
        "    height=900, width=700,\n",
        "    margin=dict(l=5, r=20, t=40, b=5),\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxwL-GTzFYv_"
      },
      "source": [
        "## Comparando el rendimiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAR0us8zItn-"
      },
      "source": [
        "pca_lr_pipe = Pipeline([('pca', PCA(n_components=20,random_state=6011)),\n",
        "                   ('lr', LinearRegression())])\n",
        "\n",
        "cross_val_pca  = cross_val_score(pca_lr_pipe, X_train, y_train, cv=ts_cv, scoring='neg_root_mean_squared_error')\n",
        "print(cross_val_pca*-1)\n",
        "print('=================================================')\n",
        "print('Resultado de la regresión lineal utilizando PCA')\n",
        "print(f'Media: {cross_val_pca.mean()*-1}, Std: {cross_val_pca.std()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgGBpzHEoeL"
      },
      "source": [
        "nmf_lr_pipe = Pipeline([('nmf', NMF(n_components=20,random_state=6011)),\n",
        "                   ('lr', LinearRegression())])\n",
        "\n",
        "cross_val_nmf  = cross_val_score(nmf_lr_pipe, X_train, y_train, cv=ts_cv, scoring='neg_root_mean_squared_error')\n",
        "print(cross_val_nmf*-1)\n",
        "print('=================================================')\n",
        "print('Resultado de la regresión lineal utilizando NMF')\n",
        "print(f'Media: {cross_val_nmf.mean()*-1}, Std: {cross_val_nmf.std()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaNGnARGcNf8"
      },
      "source": [
        "from sklearn.cross_decomposition import PLSRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFkeGYFXDodS"
      },
      "source": [
        "pls_lr_pipe = Pipeline([('pls', PLSRegression(n_components=20)),])\n",
        "\n",
        "cross_val_pls  = cross_val_score(pls_lr_pipe, X_train, y_train, cv=ts_cv, scoring='neg_root_mean_squared_error')\n",
        "print(cross_val_pls*-1)\n",
        "print('=================================================')\n",
        "print('Resultado de la regresión lineal utilizando PLS')\n",
        "print(f'Media: {cross_val_pls.mean()*-1}, Std: {cross_val_pls.std()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXgpgueSedZV"
      },
      "source": [
        "comp_df = pd.DataFrame()\n",
        "comp_df['RMSE'] = np.concatenate([cross_val_pca,cross_val_nmf,cross_val_pls], axis=0)\n",
        "comp_df['RMSE'] = comp_df['RMSE'] * -1\n",
        "comp_df['Algorithm'] = np.concatenate([['PCA']*25,['NMF']*25,['PLS']*25], axis=0)\n",
        "comp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tT-WAzifT9i"
      },
      "source": [
        "px.box(data_frame=comp_df, x='RMSE', y ='Algorithm', orientation='h', width=600, height=400, notched=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWTwWfN7hHnv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSUDZ5fmsan3"
      },
      "source": [
        "# Feature Interactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNpDMIhn78Rv"
      },
      "source": [
        "## Polinomyal interactions or combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-4l1SIB8CUM"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRUUJjGT8Cgk"
      },
      "source": [
        "X_poly = pd.DataFrame(np.arange(6).reshape(3,2),columns=['x1','x2'])\n",
        "X_poly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKns2ZocCw3q"
      },
      "source": [
        "poly = PolynomialFeatures(3) # interaction_only=False, include_bias=True,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZlf0NZZCzqK"
      },
      "source": [
        "poly_generated = poly.fit_transform(X_poly)\n",
        "poly_generated = pd.DataFrame(poly_generated, columns=poly.get_feature_names_out())\n",
        "poly_generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRZS0YOy8CoX"
      },
      "source": [
        "## Feature crossing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHQdWu74-OrR"
      },
      "source": [
        "Para esta funcionalidad utilizaremos el paquete [patsy](https://patsy.readthedocs.io/en/latest/overview.html) de python para describir modelos estadísticos y construir matrices de diseño (design matrices)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD_xNDN44Zrp"
      },
      "source": [
        "from patsy import dmatrices, dmatrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve3lLvW6seK7"
      },
      "source": [
        "df_okc = pd.read_csv('data/okc_train.csv',index_col=0)\n",
        "df_okc.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bryFMALc_-R-"
      },
      "source": [
        "$a * b$ es una abreviación de  $a + b + a:b$, y es útil para el caso común donde se desea incluir todas las interaccones entre las variables \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkGAuPvZ8IBx"
      },
      "source": [
        "y_cross,X_cross = dmatrices('Class~C(drinks)*C(drugs)', data=df_okc,return_type='dataframe') # a * b is short-hand for a + b + a:b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHopv44W-5b2"
      },
      "source": [
        "X_cross.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP0pYxLJ8v7r"
      },
      "source": [
        "y_cross.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0pJjebJ9Jju"
      },
      "source": [
        "X_cross = dmatrix('C(drinks)*C(drugs)', data=df_okc,return_type='dataframe')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrG_MmbJ9ath"
      },
      "source": [
        "X_cross.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTEc9c3F8Mue"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLJ1-6KFTZAg"
      },
      "source": [
        "# Non linear Featurization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za1zjsELTcHu"
      },
      "source": [
        "## K-means featurization\n",
        "\n",
        "Este ejemplo es parte del capítulo 7 del libro [Feature Engineering for Machine Learning](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/). El link con el código original está en el [github del libro](https://github.com/alicezheng/feature-engineering-book/blob/master/07.03-05_K-means_featurization.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcOHCqiwTa8B"
      },
      "source": [
        "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvVRIVHMBbmN"
      },
      "source": [
        "class KMeansFeaturizer:\n",
        "    \"\"\"Transforms numeric data into k-means cluster memberships.\n",
        "    \n",
        "    This transformer runs k-means on the input data and converts each data point\n",
        "    into the id of the closest cluster. If a target variable is present, it is \n",
        "    scaled and included as input to k-means in order to derive clusters that\n",
        "    obey the classification boundary as well as group similar points together.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    k: integer, optional, default 100\n",
        "        The number of clusters to group data into.\n",
        "\n",
        "    target_scale: float, [0, infty], optional, default 5.0\n",
        "        The scaling factor for the target variable. Set this to zero to ignore\n",
        "        the target. For classification problems, larger `target_scale` values \n",
        "        will produce clusters that better respect the class boundary.\n",
        "\n",
        "    random_state : integer or numpy.RandomState, optional\n",
        "        This is passed to k-means as the generator used to initialize the \n",
        "        kmeans centers. If an integer is given, it fixes the seed. Defaults to \n",
        "        the global numpy random number generator.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    cluster_centers_ : array, [k, n_features]\n",
        "        Coordinates of cluster centers. n_features does count the target column.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k=100, target_scale=5.0, random_state=None):\n",
        "        self.k = k\n",
        "        self.target_scale = target_scale\n",
        "        self.random_state = random_state\n",
        "        self.cluster_encoder = OneHotEncoder().fit(np.array(range(k)).reshape(-1,1)) # crea una columna binaria por cada cluster\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Runs k-means on the input data and find centroids.\n",
        "\n",
        "        If no target is given (`y` is None) then run vanilla k-means on input\n",
        "        `X`. \n",
        "\n",
        "        If target `y` is given, then include the target (weighted by \n",
        "        `target_scale`) as an extra dimension for k-means clustering. In this \n",
        "        case, run k-means twice, first with the target, then an extra iteration\n",
        "        without.\n",
        "\n",
        "        After fitting, the attribute `cluster_centers_` are set to the k-means\n",
        "        centroids in the input space represented by `X`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like or sparse matrix, shape=(n_data_points, n_features)\n",
        "\n",
        "        y : vector of length n_data_points, optional, default None\n",
        "            If provided, will be weighted with `target_scale` and included in \n",
        "            k-means clustering as hint.\n",
        "        \"\"\"\n",
        "        if y is None:\n",
        "            # No target variable, just do plain k-means\n",
        "            km_model = KMeans(n_clusters=self.k, \n",
        "                              n_init=20, \n",
        "                              random_state=self.random_state)\n",
        "            km_model.fit(X)\n",
        "\n",
        "            self.km_model_ = km_model\n",
        "            self.cluster_centers_ = km_model.cluster_centers_\n",
        "            return self\n",
        "\n",
        "        # There is target information. Apply appropriate scaling and include\n",
        "        # into input data to k-means            \n",
        "        data_with_target = np.hstack((X, y[:,np.newaxis]*self.target_scale))\n",
        "\n",
        "        # Build a pre-training k-means model on data and target\n",
        "        km_model_pretrain = KMeans(n_clusters=self.k, \n",
        "                                   n_init=20, \n",
        "                                   random_state=self.random_state)\n",
        "        km_model_pretrain.fit(data_with_target)\n",
        "\n",
        "        # Run k-means a second time to get the clusters in the original space\n",
        "        # without target info. Initialize using centroids found in pre-training.\n",
        "        # Go through a single iteration of cluster assignment and centroid \n",
        "        # recomputation.\n",
        "        km_model = KMeans(n_clusters=self.k, \n",
        "                          init=km_model_pretrain.cluster_centers_[:,:2], \n",
        "                          n_init=1, \n",
        "                          max_iter=1)\n",
        "        km_model.fit(X)\n",
        "        \n",
        "        self.km_model = km_model\n",
        "        self.cluster_centers_ = km_model.cluster_centers_\n",
        "        return self\n",
        "        \n",
        "    def transform(self, X, y=None):\n",
        "        \"\"\"Outputs the closest cluster id for each input data point.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like or sparse matrix, shape=(n_data_points, n_features)\n",
        "\n",
        "        y : vector of length n_data_points, optional, default None\n",
        "            Target vector is ignored even if provided.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        cluster_ids : array, shape[n_data_points,1]\n",
        "        \"\"\"\n",
        "        clusters = self.km_model.predict(X)\n",
        "        return self.cluster_encoder.transform(clusters.reshape(-1,1))\n",
        "    \n",
        "    def fit_transform(self, X, y=None):\n",
        "        \"\"\"Runs fit followed by transform.\n",
        "        \"\"\"\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_vnzwjkBwiS"
      },
      "source": [
        "seed = 6011\n",
        "training_data, training_labels = make_moons(n_samples=2000, noise=0.2, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR1ne7HIF2le"
      },
      "source": [
        "training_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EneQk0UwF97G"
      },
      "source": [
        "training_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr205_XoFqpn"
      },
      "source": [
        " plt.scatter(training_data[:, 0], training_data[:, 1], c=training_labels, cmap='Set1', alpha=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apr3WT9oB2-D"
      },
      "source": [
        "kmf_hint = KMeansFeaturizer(k=100, target_scale=10, random_state=seed).fit(training_data, training_labels)\n",
        "kmf_no_hint = KMeansFeaturizer(k=100, target_scale=0, random_state=seed).fit(training_data, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WXbOwlBB40e"
      },
      "source": [
        "def kmeans_voronoi_plot(X, y, cluster_centers, ax):\n",
        "    \"\"\"Plots the Voronoi diagram of the kmeans clusters overlayed with the data\"\"\"\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='Set1', alpha=0.2)\n",
        "    vor = Voronoi(cluster_centers)\n",
        "    voronoi_plot_2d(vor, ax=ax, show_vertices=False, alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebfM-dfwB7xf"
      },
      "source": [
        "fig = plt.figure(figsize=(24,10))\n",
        "ax = plt.subplot(211, aspect='equal')\n",
        "kmeans_voronoi_plot(training_data, training_labels, kmf_hint.cluster_centers_, ax)\n",
        "ax.set_title('K-Means with Target Hint')\n",
        "ax2 = plt.subplot(212, aspect='equal')\n",
        "kmeans_voronoi_plot(training_data, training_labels, kmf_no_hint.cluster_centers_, ax2)\n",
        "ax2.set_title('K-Means without Target Hint')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXdn1HR4B9va"
      },
      "source": [
        "## Classification with KMeans clustering features¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTZuWaH7CQ6X"
      },
      "source": [
        "test_data, test_labels = make_moons(n_samples=2000, noise=0.3, random_state=seed+5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqVRqIjXCSxA"
      },
      "source": [
        "training_cluster_features = kmf_hint.transform(training_data)\n",
        "test_cluster_features = kmf_hint.transform(test_data)\n",
        "\n",
        "training_with_cluster = hstack((training_data, training_cluster_features)) #scipy.sparse.hstack\n",
        "test_with_cluster = hstack((test_data, test_cluster_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZHJFA1iCVHz"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqzmQFUUClt3"
      },
      "source": [
        "lr_cluster = LogisticRegression(random_state=seed).fit(training_with_cluster, training_labels)\n",
        "\n",
        "classifier_names = ['LR',\n",
        "                    'kNN',\n",
        "                    'RBF SVM',\n",
        "                    'Random Forest',\n",
        "                    'Boosted Trees']\n",
        "classifiers = [LogisticRegression(random_state=seed),\n",
        "               KNeighborsClassifier(5),\n",
        "               SVC(gamma=2, C=1, random_state=seed),\n",
        "               RandomForestClassifier(max_depth=5, n_estimators=10, \n",
        "                                      max_features=1, random_state=seed),\n",
        "               GradientBoostingClassifier(n_estimators=10, learning_rate=1.0,\n",
        "                                          max_depth=5, random_state=seed)]\n",
        "for model in classifiers:\n",
        "    model.fit(training_data, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIMKFB5KCnre"
      },
      "source": [
        "def test_roc(model, data, labels):\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        predictions = model.decision_function(data)\n",
        "    else:\n",
        "        predictions = model.predict_proba(data)[:,1]\n",
        "    fpr, tpr, _ = roc_curve(labels, predictions) # sklearn.metrics.roc_curve\n",
        "    auc_score = roc_auc_score(labels, predictions)\n",
        "    print(f'{model.__class__.__name__}: {auc_score}')\n",
        "    return fpr, tpr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYKpUIj7CpaP"
      },
      "source": [
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "fpr_cluster, tpr_cluster = test_roc(lr_cluster, test_with_cluster, test_labels)\n",
        "plt.plot(fpr_cluster, tpr_cluster, 'r-', label='LR with k-means')\n",
        "\n",
        "for i, model in enumerate(classifiers):\n",
        "    fpr, tpr = test_roc(model, test_data, test_labels)\n",
        "    plt.plot(fpr, tpr, label=classifier_names[i])\n",
        "    \n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate', fontsize=14)\n",
        "plt.ylabel('True Positive Rate', fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y__HsLmYT8o8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}